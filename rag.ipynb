{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUEV2amfgIrP",
        "outputId": "0cfb1c3c-d5a7-4b6f-813a-7e6a6e73e0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Top 50 most common ingredients:\n",
            "[('2 eggs', 95855), ('1 tsp. vanilla', 85285), ('1/2 tsp. salt', 80645), ('1 tsp. salt', 80373), ('1 egg', 77876), ('1/2 teaspoon salt', 70412), ('1 c. sugar', 65050), ('1 teaspoon salt', 63534), ('1/4 teaspoon salt', 47646), ('2 c. sugar', 44173), ('salt and pepper', 44054), ('3 eggs', 43764), ('4 eggs', 42933), ('1/4 tsp. salt', 39618), ('salt', 39402), ('salt and pepper to taste', 34547), ('1/2 c. sugar', 33990), ('2 tablespoons olive oil', 32874), ('1 teaspoon vanilla extract', 32555), ('1 tablespoon olive oil', 30824), ('1 cup sugar', 28603), ('2 c. flour', 28130), ('1 c. milk', 27001), ('1 tsp. cinnamon', 24237), ('1/2 c. milk', 23178), ('1 teaspoon vanilla', 23052), ('2 tablespoons butter', 22780), ('1 can cream of mushroom soup', 22422), ('1/4 tsp. pepper', 22329), ('1 teaspoon baking soda', 21971), ('1 tsp. baking soda', 21285), ('pepper', 21183), ('1 tsp. soda', 20706), ('1 medium onion, chopped', 20668), ('1 tsp. baking powder', 20313), ('1/2 cup sugar', 20116), ('1 can cream of chicken soup', 19797), ('1 1/2 c. sugar', 19768), ('1 lb. ground beef', 19242), ('1 cup water', 19223), ('1 c. water', 19076), ('2 garlic cloves, minced', 18989), ('1 teaspoon baking powder', 18786), ('1 c. flour', 18745), ('1 bay leaf', 18391), ('12 teaspoon salt', 18224), ('2 eggs, beaten', 18073), ('1 egg, beaten', 18054), ('3/4 c. sugar', 18033), ('1 onion, chopped', 18013)]\n",
            "✅ Dataset contains 2231142 recipes with 1312870 unique dish names.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from collections import Counter\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/dataset/full_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df[\"ingredients\"] = df[\"ingredients\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "\n",
        "ingredient_counter = Counter()\n",
        "for ingredients in df[\"ingredients\"]:\n",
        "    ingredient_counter.update(ingredients)\n",
        "\n",
        "\n",
        "print(\"🔹 Top 50 most common ingredients:\")\n",
        "print(ingredient_counter.most_common(50))\n",
        "\n",
        "print(f\"✅ Dataset contains {len(df)} recipes with {df['title'].nunique()} unique dish names.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDwJ3fC5OUXz",
        "outputId": "5a58722f-606b-48b2-b664-545298ebd44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset reduced to 50000 rows and saved as filtered_recipenlg_50k.csv\n"
          ]
        }
      ],
      "source": [
        "ingredient_counter = Counter()\n",
        "for ingredients in df[\"ingredients\"]:\n",
        "    ingredient_counter.update(ingredients)\n",
        "\n",
        "def filter_recipe(ingredients):\n",
        "    common_count = sum(1 for ing in ingredients if ing in ingredient_counter)\n",
        "    return 2 <= common_count <= 15  # Ensures balance (not too generic or too niche)\n",
        "\n",
        "df_filtered = df[df[\"ingredients\"].apply(filter_recipe)]\n",
        "\n",
        "df_sampled = df_filtered.sample(n=50000, random_state=42)\n",
        "\n",
        "df_sampled.to_csv(\"filtered_recipenlg_50k.csv\", index=False)\n",
        "\n",
        "print(f\"✅ Dataset reduced to {len(df_sampled)} rows and saved as filtered_recipenlg_50k.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vd9Q-84SFaf",
        "outputId": "7818f082-838c-4cf1-846a-b6b4a2f056eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 'id' column added and dataset saved!\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/filtered_recipenlg_50k.csv\")\n",
        "\n",
        "\n",
        "if \"id\" not in df.columns:\n",
        "    df.insert(0, \"id\", range(1, len(df) + 1))\n",
        "\n",
        "df.to_csv(\"filtered_recipenlg_50k.csv\", index=False)\n",
        "\n",
        "print(\"✅ 'id' column added and dataset saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OSj5YNESOGw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVwWkRLmPP4p",
        "outputId": "ddc01721-1bcc-4300-a4e6-cfd7d0741269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Processing batch 1...\n",
            "✅ Batch 1 saved successfully!\n",
            "🔹 Processing batch 2...\n",
            "✅ Batch 2 saved successfully!\n",
            "🔹 Processing batch 3...\n",
            "✅ Batch 3 saved successfully!\n",
            "🔹 Processing batch 4...\n",
            "✅ Batch 4 saved successfully!\n",
            "🔹 Processing batch 5...\n",
            "✅ Batch 5 saved successfully!\n",
            "🔹 Processing batch 6...\n",
            "✅ Batch 6 saved successfully!\n",
            "🔹 Processing batch 7...\n",
            "✅ Batch 7 saved successfully!\n",
            "🔹 Processing batch 8...\n",
            "✅ Batch 8 saved successfully!\n",
            "🔹 Processing batch 9...\n",
            "✅ Batch 9 saved successfully!\n",
            "🔹 Processing batch 10...\n",
            "✅ Batch 10 saved successfully!\n",
            "🔹 Processing batch 11...\n",
            "✅ Batch 11 saved successfully!\n",
            "🔹 Processing batch 12...\n",
            "✅ Batch 12 saved successfully!\n",
            "🔹 Processing batch 13...\n",
            "✅ Batch 13 saved successfully!\n",
            "🔹 Processing batch 14...\n",
            "✅ Batch 14 saved successfully!\n",
            "🔹 Processing batch 15...\n",
            "✅ Batch 15 saved successfully!\n",
            "🔹 Processing batch 16...\n",
            "✅ Batch 16 saved successfully!\n",
            "🔹 Processing batch 17...\n",
            "✅ Batch 17 saved successfully!\n",
            "🔹 Processing batch 18...\n",
            "✅ Batch 18 saved successfully!\n",
            "🔹 Processing batch 19...\n",
            "✅ Batch 19 saved successfully!\n",
            "🔹 Processing batch 20...\n",
            "✅ Batch 20 saved successfully!\n",
            "🔹 Processing batch 21...\n",
            "✅ Batch 21 saved successfully!\n",
            "🔹 Processing batch 22...\n",
            "✅ Batch 22 saved successfully!\n",
            "🔹 Processing batch 23...\n",
            "✅ Batch 23 saved successfully!\n",
            "🔹 Processing batch 24...\n",
            "✅ Batch 24 saved successfully!\n",
            "🔹 Processing batch 25...\n",
            "✅ Batch 25 saved successfully!\n",
            "🔹 Processing batch 26...\n",
            "✅ Batch 26 saved successfully!\n",
            "🔹 Processing batch 27...\n",
            "✅ Batch 27 saved successfully!\n",
            "🔹 Processing batch 28...\n",
            "✅ Batch 28 saved successfully!\n",
            "🔹 Processing batch 29...\n",
            "✅ Batch 29 saved successfully!\n",
            "🔹 Processing batch 30...\n",
            "✅ Batch 30 saved successfully!\n",
            "🔹 Processing batch 31...\n",
            "✅ Batch 31 saved successfully!\n",
            "🔹 Processing batch 32...\n",
            "✅ Batch 32 saved successfully!\n",
            "🔹 Processing batch 33...\n",
            "✅ Batch 33 saved successfully!\n",
            "🔹 Processing batch 34...\n",
            "✅ Batch 34 saved successfully!\n",
            "🔹 Processing batch 35...\n",
            "✅ Batch 35 saved successfully!\n",
            "🔹 Processing batch 36...\n",
            "✅ Batch 36 saved successfully!\n",
            "🔹 Processing batch 37...\n",
            "✅ Batch 37 saved successfully!\n",
            "🔹 Processing batch 38...\n",
            "✅ Batch 38 saved successfully!\n",
            "🔹 Processing batch 39...\n",
            "✅ Batch 39 saved successfully!\n",
            "🔹 Processing batch 40...\n",
            "✅ Batch 40 saved successfully!\n",
            "🔹 Processing batch 41...\n",
            "✅ Batch 41 saved successfully!\n",
            "🔹 Processing batch 42...\n",
            "✅ Batch 42 saved successfully!\n",
            "🔹 Processing batch 43...\n",
            "✅ Batch 43 saved successfully!\n",
            "🔹 Processing batch 44...\n",
            "✅ Batch 44 saved successfully!\n",
            "🔹 Processing batch 45...\n",
            "✅ Batch 45 saved successfully!\n",
            "🔹 Processing batch 46...\n",
            "✅ Batch 46 saved successfully!\n",
            "🔹 Processing batch 47...\n",
            "✅ Batch 47 saved successfully!\n",
            "🔹 Processing batch 48...\n",
            "✅ Batch 48 saved successfully!\n",
            "🔹 Processing batch 49...\n",
            "✅ Batch 49 saved successfully!\n",
            "🔹 Processing batch 50...\n",
            "✅ Batch 50 saved successfully!\n",
            "✅ Embedding process complete for 50 batches!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "\n",
        "file_path = \"/content/filtered_recipenlg_50k.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "JINA_API_URL = \"https://api.jina.ai/v1/embeddings\"\n",
        "HEADERS = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer **\"\n",
        "}\n",
        "\n",
        "df['recipe_text'] = df['title'] + \" \" + df['ingredients'] + \" \" + df['directions']\n",
        "\n",
        "EMBEDDINGS_FILE = \"recipe_embeddings.npy\"\n",
        "IDS_FILE = \"recipe_ids.npy\"\n",
        "LOG_FILE = \"processed_batches.txt\"\n",
        "\n",
        "if os.path.exists(EMBEDDINGS_FILE) and os.path.exists(IDS_FILE):\n",
        "    embeddings_list = list(np.load(EMBEDDINGS_FILE).tolist())\n",
        "    recipe_ids = list(np.load(IDS_FILE).tolist())\n",
        "    processed_batches = set(map(int, open(LOG_FILE).read().split())) if os.path.exists(LOG_FILE) else set()\n",
        "else:\n",
        "    embeddings_list = []\n",
        "    recipe_ids = []\n",
        "    processed_batches = set()\n",
        "\n",
        "\n",
        "def get_embeddings(text_list):\n",
        "    data = {\n",
        "        \"model\": \"jina-clip-v2\",\n",
        "        \"dimensions\": 1024,\n",
        "        \"normalized\": True,\n",
        "        \"embedding_type\": \"float\",\n",
        "        \"input\": [{\"text\": text} for text in text_list]\n",
        "    }\n",
        "\n",
        "    response = requests.post(JINA_API_URL, headers=HEADERS, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return json.loads(response.text)[\"data\"]\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.status_code} - {response.text}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "MAX_BATCHES = 50\n",
        "\n",
        "for i in range(0, BATCH_SIZE * MAX_BATCHES, BATCH_SIZE):\n",
        "    batch_num = i // BATCH_SIZE + 1\n",
        "\n",
        "    if batch_num > MAX_BATCHES:\n",
        "        break\n",
        "\n",
        "    if batch_num in processed_batches:\n",
        "        print(f\"✅ Skipping batch {batch_num}, already processed.\")\n",
        "        continue\n",
        "\n",
        "    batch_texts = df['recipe_text'][i:i+BATCH_SIZE].tolist()\n",
        "    batch_ids = df['id'][i:i+BATCH_SIZE].tolist()\n",
        "\n",
        "    print(f\"🔹 Processing batch {batch_num}...\")\n",
        "\n",
        "    batch_embeddings = get_embeddings(batch_texts)\n",
        "\n",
        "    if batch_embeddings:\n",
        "        embeddings_list.extend(batch_embeddings)\n",
        "        recipe_ids.extend(batch_ids)\n",
        "\n",
        "        np.save(EMBEDDINGS_FILE, np.array(embeddings_list))\n",
        "        np.save(IDS_FILE, np.array(recipe_ids))\n",
        "\n",
        "        with open(LOG_FILE, \"a\") as f:\n",
        "            f.write(f\"{batch_num}\\n\")\n",
        "\n",
        "        print(f\"✅ Batch {batch_num} saved successfully!\")\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"✅ Embedding process complete for 50 batches!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNNVgPBOU0re",
        "outputId": "63db23ba-1230-490b-e9c9-69668af01e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMGwf9soWMaw",
        "outputId": "30e6bdda-a32d-4ffa-8742-04517d4babd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Embeddings shape: (5000, 1024)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = np.load(\"/content/drive/MyDrive/dataset/recipe_embeddings.npy\", allow_pickle=True)\n",
        "\n",
        "print(\"✅ Embeddings shape:\", embeddings.shape)  # Check shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF5NJaNuWSwA",
        "outputId": "6b7a89e0-d220-47fc-fd2a-e9e6f1bdc767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fixed Embeddings Shape: (5000, 1024)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = np.load(\"/content/drive/MyDrive/dataset/recipe_embeddings.npy\", allow_pickle=True)\n",
        "\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "np.save(\"recipe_embeddings.npy\", embeddings)\n",
        "\n",
        "print(\"✅ Fixed Embeddings Shape:\", embeddings.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPv391HYWcQM",
        "outputId": "b97ed9f8-41ee-4ca6-a32e-953202c8c9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entry 0: Type -> <class 'numpy.ndarray'>, Value -> [ 0.05629175  0.0982436  -0.00143876 ... -0.00510287 -0.01075493\n",
            "  0.00813103]\n",
            "Entry 1: Type -> <class 'numpy.ndarray'>, Value -> [ 0.17123969  0.13887526 -0.02934685 ...  0.00671081 -0.01772417\n",
            "  0.03442037]\n",
            "Entry 2: Type -> <class 'numpy.ndarray'>, Value -> [0.07313133 0.02419892 0.00527012 ... 0.00994329 0.00991657 0.00239227]\n",
            "Entry 3: Type -> <class 'numpy.ndarray'>, Value -> [ 0.01256496  0.13852888 -0.00968193 ...  0.00173453  0.0113884\n",
            "  0.00850088]\n",
            "Entry 4: Type -> <class 'numpy.ndarray'>, Value -> [-0.03603871  0.08283365 -0.02122657 ...  0.00075825  0.00271362\n",
            "  0.00188614]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = np.load(\"recipe_embeddings.npy\", allow_pickle=True)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Entry {i}: Type -> {type(embeddings[i])}, Value -> {embeddings[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_TylciZ5CRo",
        "outputId": "8bfa73b0-4f7d-40ad-ab56-cece6dc45bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entry 0: Type -> <class 'numpy.ndarray'>, Value -> [ 0.05629175  0.0982436  -0.00143876 ... -0.00510287 -0.01075493\n",
            "  0.00813103]\n",
            "Entry 1: Type -> <class 'numpy.ndarray'>, Value -> [ 0.17123969  0.13887526 -0.02934685 ...  0.00671081 -0.01772417\n",
            "  0.03442037]\n",
            "Entry 2: Type -> <class 'numpy.ndarray'>, Value -> [0.07313133 0.02419892 0.00527012 ... 0.00994329 0.00991657 0.00239227]\n",
            "Entry 3: Type -> <class 'numpy.ndarray'>, Value -> [ 0.01256496  0.13852888 -0.00968193 ...  0.00173453  0.0113884\n",
            "  0.00850088]\n",
            "Entry 4: Type -> <class 'numpy.ndarray'>, Value -> [-0.03603871  0.08283365 -0.02122657 ...  0.00075825  0.00271362\n",
            "  0.00188614]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "raw_embeddings = np.load(\"/content/drive/MyDrive/dataset/recipe_embeddings.npy\", allow_pickle=True)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Entry {i}: Type -> {type(raw_embeddings[i])}, Value -> {raw_embeddings[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL46z63pWpbw",
        "outputId": "5d244fac-e2a5-4067-f497-f42a135bdd2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fixed Embeddings Shape: (5000, 1024)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "raw_embeddings = np.load(\"/content/drive/MyDrive/dataset/recipe_embeddings.npy\", allow_pickle=True)\n",
        "\n",
        "fixed_embeddings = np.vstack(raw_embeddings)\n",
        "\n",
        "np.save(\"recipe_embeddings.npy\", fixed_embeddings)\n",
        "\n",
        "print(\"✅ Fixed Embeddings Shape:\", fixed_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb50UpFd5Ygr",
        "outputId": "fd452606-3f17-4c13-cb89-403e9ba1c8e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 'id' column added and dataset saved!\n"
          ]
        }
      ],
      "source": [
        "if \"id\" not in df.columns:\n",
        "    df.insert(0, \"id\", range(1, len(df) + 1))  \n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/dataset/filtered_recipenlg_50k.csv\", index=False)\n",
        "\n",
        "print(\"✅ 'id' column added and dataset saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ao3fhXdR7Sr",
        "outputId": "05f4e1f1-582d-4e7d-eb9a-4c6f5b01e9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter ingredients: chicken. rice\n",
            "🔹 Top Matching Recipes:\n",
            "                           title  \\\n",
            "870   Chicken And Rice Casserole   \n",
            "1124            Chicken And Rice   \n",
            "1871      Baked Chicken And Rice   \n",
            "2347            Chicken And Rice   \n",
            "2503            Chicken And Rice   \n",
            "\n",
            "                                            ingredients  \\\n",
            "870   ['4 c. cooked chicken', '1/4 c. onion', '2 Tbs...   \n",
            "1124  ['chicken pieces', '1 c. long grain rice', '2 ...   \n",
            "1871  ['whole chicken, cut up into pieces', '1 chopp...   \n",
            "2347  ['1 1/3 c. Minute rice', '2 cans (10 3/4 oz.) ...   \n",
            "2503  ['1 c. rice*', 'chicken pieces*', '1 can water...   \n",
            "\n",
            "                                             directions  \n",
            "870   [\"Simmer the onion in butter.\", \"Add chicken; ...  \n",
            "1124  [\"There is no salt in this recipe.\", \"Scatter ...  \n",
            "1871  [\"Place chicken pieces in a greased baking dis...  \n",
            "2347  [\"Mix all\", \"ingredients except chicken and pa...  \n",
            "2503  [\"Grease 9 x 13-inch pan.\", \"Pour in rice and ...  \n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "\n",
        "embeddings = np.load(\"/content/recipe_embeddings.npy\", allow_pickle=True)\n",
        "recipe_ids = np.load(\"/content/drive/MyDrive/dataset/recipe_ids.npy\", allow_pickle=True)\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/filtered_recipenlg_50k.csv\")\n",
        "\n",
        "df = df[df[\"id\"].isin(recipe_ids)]\n",
        "\n",
        "sorted_indices = np.argsort(recipe_ids)\n",
        "recipe_ids = recipe_ids[sorted_indices]\n",
        "embeddings = embeddings[sorted_indices]\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "\n",
        "JINA_API_URL = \"https://api.jina.ai/v1/embeddings\"\n",
        "HEADERS = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer **\"\n",
        "}\n",
        "\n",
        "\n",
        "def get_query_embedding(text):\n",
        "    data = {\n",
        "        \"model\": \"jina-clip-v2\",\n",
        "        \"dimensions\": 1024,\n",
        "        \"normalized\": True,\n",
        "        \"embedding_type\": \"float\",\n",
        "        \"input\": [{\"text\": text}]\n",
        "    }\n",
        "\n",
        "    response = requests.post(JINA_API_URL, headers=HEADERS, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = json.loads(response.text)\n",
        "\n",
        "        embedding_vector = np.array(response_data[\"data\"][0][\"embedding\"], dtype=np.float32)\n",
        "\n",
        "        return embedding_vector\n",
        "    else:\n",
        "        print(f\"❌ Error: {response.status_code} - {response.text}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def retrieve_similar_recipes(user_query, k=5):\n",
        "    query_embedding = get_query_embedding(user_query)\n",
        "\n",
        "    if query_embedding is None:\n",
        "        print(\"❌ Error generating query embedding. Try again.\")\n",
        "        return None\n",
        "\n",
        "    query_embedding = query_embedding.reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    matched_ids = [recipe_ids[i] for i in indices[0] if i < len(recipe_ids)]\n",
        "\n",
        "    results = df[df[\"id\"].isin(matched_ids)]\n",
        "    return results[[\"title\", \"ingredients\", \"directions\"]]\n",
        "\n",
        "user_input = input(\"Enter ingredients: \")\n",
        "similar_recipes = retrieve_similar_recipes(user_input, k=5)\n",
        "\n",
        "print(\"🔹 Top Matching Recipes:\")\n",
        "print(similar_recipes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWNAnhnV8IsZ",
        "outputId": "981503c3-0492-4752-d4cc-8bb23585c1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUjd9avEV6rk",
        "outputId": "4ce904e8-fc60-4e85-dbd3-1a3faf5018f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter ingredients: chicken , rice\n",
            "🔹 AI-Generated Recipe:\n",
            "**Simple Chicken and Rice Bake**\n",
            "Ingredients:\n",
            "- 1 1/2 cups uncooked white or brown rice\n",
            "- 2 lbs boneless, skinless chicken breast or thighs, cut into 1-inch pieces\n",
            "- 2 cups chicken broth\n",
            "- 1 tablespoon olive oil\n",
            "- Salt and pepper to taste\n",
            "- Optional: garlic powder, paprika, or other spices of your choice\n",
            "\n",
            "Directions:\n",
            "1. Preheat your oven to 375°F (190°C).\n",
            "2. In a large mixing bowl, combine the rice, chicken broth, and a pinch of salt. Stir well to combine.\n",
            "3. In a separate bowl, toss the chicken pieces with olive oil, salt, pepper, and any desired spices (like garlic powder or paprika) until the chicken is evenly coated.\n",
            "4. In a 9x13-inch baking dish, create a layer of the rice mixture. You can use all of it or save some for the top, depending on your preference.\n",
            "5. Add the chicken pieces on top of the rice layer. If you saved some rice, you can add it on top of the chicken.\n",
            "6. Cover the baking dish with aluminum foil and bake for 45 minutes.\n",
            "7. Remove the foil and continue baking for an additional 15-20 minutes, or until the chicken is cooked through and the rice is tender.\n",
            "8. Remove from the oven and let it rest for a few minutes before serving.\n",
            "\n",
            "**Adjustments for Dietary Needs:**\n",
            "- For a gluten-free version, ensure the chicken broth is gluten-free.\n",
            "- For a low-sodium version, use low-sodium chicken broth and reduce or omit the added salt.\n",
            "- For a spicy version, add diced jalapeños or red pepper flakes to the chicken or rice mixture.\n",
            "- To make it vegetarian or vegan, replace the chicken with firm tofu, tempeh, or seitan, and use a vegetable broth instead of chicken broth.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "client = Groq(api_key=\"**\")\n",
        "\n",
        "def generate_recipe(user_query, retrieved_recipes):\n",
        "    retrieved_text = \"\\n\\n\".join(\n",
        "        f\"Title: {row['title']}\\nIngredients: {row['ingredients']}\\nDirections: {row['directions']}\"\n",
        "        for _, row in retrieved_recipes.iterrows()\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The user wants a recipe with the following ingredients: {user_query}.\n",
        "\n",
        "    Here are some similar recipes:\n",
        "    {retrieved_text}\n",
        "\n",
        "    Based on these, generate a **new recipe** that:\n",
        "    - Uses the user-provided ingredients.\n",
        "    - Follows a structured format: **Title, Ingredients, Directions**.\n",
        "    - Can be adjusted for dietary needs if required.\n",
        "    \"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert chef AI.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_completion_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=True,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    generated_text = \"\"\n",
        "    for chunk in completion:\n",
        "        generated_text += chunk.choices[0].delta.content or \"\"\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "user_input = input(\"Enter ingredients: \")\n",
        "retrieved_recipes = retrieve_similar_recipes(user_input, k=5)\n",
        "\n",
        "if retrieved_recipes is not None:\n",
        "    generated_recipe = generate_recipe(user_input, retrieved_recipes)\n",
        "    print(\"🔹 AI-Generated Recipe:\")\n",
        "    print(generated_recipe)\n",
        "else:\n",
        "    print(\"❌ No recipes retrieved. Try again.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
